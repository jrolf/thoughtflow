{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d9539b7",
   "metadata": {},
   "source": [
    "# Script 04 — Deploy to the Cloud with ThoughtBase\n",
    "\n",
    "This script takes the research agent from Script 03 and deploys it\n",
    "as a **live cloud API** using ThoughtBase.\n",
    "\n",
    "You will:\n",
    "1. Verify your ThoughtBase account\n",
    "2. Store API keys as server-side secrets\n",
    "3. Deploy a simple function as a sanity check\n",
    "4. Deploy a ThoughtFlow-powered research agent\n",
    "5. Have a multi-turn conversation with the deployed agent\n",
    "6. See how to call the agent from curl or plain Python\n",
    "\n",
    "**Every cell makes real API calls** — your agent becomes a real\n",
    "HTTP endpoint accessible from anywhere.\n",
    "\n",
    "Prerequisites:\n",
    "  - ThoughtBase API key in `.env`\n",
    "  - Groq and Brave API keys in `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aefc58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _setup import load_env, print_heading, print_separator\n",
    "import os\n",
    "\n",
    "env = load_env()\n",
    "\n",
    "from thoughtbase import (\n",
    "    set_api_key,\n",
    "    get_balance,\n",
    "    set_secrets,\n",
    "    list_secrets,\n",
    "    test_agent,\n",
    "    deploy_agent,\n",
    "    call_agent,\n",
    "    list_agents,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaf5fa8",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1 — Connect to ThoughtBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abdd9883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  1.1  Set API key and verify account\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Balance: {'user_id': 'j2RJkFaozg1ASOLAD', 'balance_usd': '$9.98789'}\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"1.1  Set API key and verify account\")\n",
    "\n",
    "thb_key = os.environ.get(\"THB_API_KEY\", \"\")\n",
    "set_api_key(thb_key)\n",
    "\n",
    "balance = get_balance()\n",
    "print(\"Balance:\", balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa4e436",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2 — Secrets Management\n",
    "\n",
    "Your deployed agent needs API keys for Groq and Brave Search.\n",
    "ThoughtBase stores these as **secrets** — they are injected into\n",
    "every execution sandbox as a `SECRETS` dict, so you never embed\n",
    "credentials in your agent code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b067cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  2.1  Store secrets\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "set_secrets: {'stored': ['GROQ_API_KEY', 'BRAVE_API_KEY']}\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"2.1  Store secrets\")\n",
    "\n",
    "groq_key = os.environ.get(\"GROQ_API_KEY\", \"\")\n",
    "brave_key = os.environ.get(\"BRAVE_API_KEY\", \"\")\n",
    "\n",
    "result = set_secrets({\n",
    "    \"GROQ_API_KEY\": groq_key,\n",
    "    \"BRAVE_API_KEY\": brave_key,\n",
    "})\n",
    "print(\"set_secrets:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394fbd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  2.2  Verify secrets are stored\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Stored secret names: {'secret_names': ['GROQ_API_KEY', 'BRAVE_API_KEY']}\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"2.2  Verify secrets are stored\")\n",
    "\n",
    "stored = list_secrets()\n",
    "print(\"Stored secret names:\", stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "470fefe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  2.3  Prove that SECRETS are injected at runtime\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Secrets visible in sandbox: {'keys': ['GROQ_API_KEY', 'BRAVE_API_KEY'], 'count': 2}\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"2.3  Prove that SECRETS are injected at runtime\")\n",
    "\n",
    "# This code runs in the cloud sandbox and reads SECRETS.\n",
    "# Values are never logged — we just confirm the keys are present.\n",
    "result = test_agent(\n",
    "    code='def check(x): return {\"keys\": list(SECRETS.keys()), \"count\": len(SECRETS)}',\n",
    "    fname=\"check\",\n",
    "    input_obj={},\n",
    ")\n",
    "print(\"Secrets visible in sandbox:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d4fb1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  2.4  Quick smoke test — run code without deploying\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "17 + 25 = 42\n",
      "Cloud execution works!\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"2.4  Quick smoke test — run code without deploying\")\n",
    "\n",
    "result = test_agent(\n",
    "    code=\"def add(x): return x['a'] + x['b']\",\n",
    "    fname=\"add\",\n",
    "    input_obj={\"a\": 17, \"b\": 25},\n",
    ")\n",
    "print(\"17 + 25 =\", result)\n",
    "assert result == 42, \"Smoke test failed — check your THB_API_KEY\"\n",
    "print(\"Cloud execution works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d958198e",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3 — Deploy a Simple Agent\n",
    "\n",
    "Before deploying the full research agent, let us start with something\n",
    "trivial to confirm the deploy → call round-trip works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffb46e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  3.1  Deploy a simple function\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Deployed! Agent ID: DvrtH1oMXHbC2doIu4x7ipDNNmGsU58QSE\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"3.1  Deploy a simple function\")\n",
    "\n",
    "simple_code = '''\n",
    "def greet(name):\n",
    "    \"\"\"A trivially simple deployed function.\"\"\"\n",
    "    return \"Hello from the cloud, {}!\".format(name)\n",
    "\n",
    "def multiply(data):\n",
    "    \"\"\"Multiply two numbers passed as a dict.\"\"\"\n",
    "    return data[\"a\"] * data[\"b\"]\n",
    "'''\n",
    "\n",
    "deploy_result = deploy_agent(simple_code)\n",
    "simple_agent_id = deploy_result.get(\"api_id\", \"\")\n",
    "print(\"Deployed! Agent ID:\", simple_agent_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba812541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  3.2  Call the deployed functions\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "greet('World') → Hello from the cloud, World!\n",
      "multiply(7, 6) → 42\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"3.2  Call the deployed functions\")\n",
    "\n",
    "greeting = call_agent(simple_agent_id, \"greet\", \"World\")\n",
    "print(\"greet('World') →\", greeting)\n",
    "\n",
    "product = call_agent(simple_agent_id, \"multiply\", {\"a\": 7, \"b\": 6})\n",
    "print(\"multiply(7, 6) →\", product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae67307",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4 — Deploy the Research Agent\n",
    "\n",
    "Now the real thing.  We package the research agent as a self-contained\n",
    "string of Python code and deploy it to ThoughtBase.\n",
    "\n",
    "**How API keys reach the cloud:**\n",
    "The agent code reads credentials from the `SECRETS` dict, which\n",
    "ThoughtBase automatically injects into every execution sandbox.\n",
    "You stored the keys in Part 2 — the agent code never sees them\n",
    "in plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eac3af07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  4.1  The agent code (cloud version)\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Agent code prepared (5706 chars)\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"4.1  The agent code (cloud version)\")\n",
    "\n",
    "# The agent reads API keys from SECRETS — no credentials in the code\n",
    "# or in the request payload.\n",
    "\n",
    "agent_code = '''\n",
    "from thoughtflow import LLM, MEMORY, THOUGHT, DECIDE, PLAN, SEARCH\n",
    "\n",
    "# --- Credentials from SECRETS (injected by ThoughtBase) ---\n",
    "llm = LLM(\"groq:llama-3.3-70b-versatile\", key=SECRETS[\"GROQ_API_KEY\"])\n",
    "brave_key = SECRETS[\"BRAVE_API_KEY\"]\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are Ariel, a sharp and curious research analyst.\n",
    "\n",
    "Your personality:\n",
    "- You are direct and opinionated.\n",
    "- You ask probing questions before researching.\n",
    "- When you find conflicting information, you surface the conflict honestly.\n",
    "- You are concise but thorough.\n",
    "\n",
    "Rules:\n",
    "- Never fabricate sources.\n",
    "- If you are unsure, say so.\n",
    "- Keep responses focused.\"\"\"\n",
    "\n",
    "# --- Components ---\n",
    "\n",
    "intent_classifier = DECIDE(\n",
    "    name=\"intent\",\n",
    "    llm=llm,\n",
    "    choices={\n",
    "        \"new_topic\": \"User is introducing a new research topic\",\n",
    "        \"clarify\": \"User is answering a clarifying question\",\n",
    "        \"research\": \"User wants to go ahead and research\",\n",
    "        \"deeper\": \"User wants to dig deeper into a sub-topic\",\n",
    "        \"done\": \"User wants to wrap up\",\n",
    "    },\n",
    "    prompt=(\n",
    "        \"Based on the conversation and the latest message, \"\n",
    "        \"determine the user intent.\\\\n\\\\n\"\n",
    "        \"Conversation:\\\\n{conversation_context}\\\\n\\\\n\"\n",
    "        \"Latest message: {last_user_msg}\"\n",
    "    ),\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    max_retries=3,\n",
    ")\n",
    "\n",
    "discovery_thought = THOUGHT(\n",
    "    name=\"discovery\",\n",
    "    llm=llm,\n",
    "    prompt=(\n",
    "        \"The user wants to research: {last_user_msg}\\\\n\\\\n\"\n",
    "        \"Context so far:\\\\n{conversation_context}\\\\n\\\\n\"\n",
    "        \"Ask 2-3 sharp clarifying questions.\"\n",
    "    ),\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    ")\n",
    "\n",
    "research_planner = PLAN(\n",
    "    name=\"research_plan\",\n",
    "    llm=llm,\n",
    "    actions={\n",
    "        \"search\": {\"description\": \"Search the web\", \"params\": {\"query\": \"str\"}},\n",
    "        \"analyze\": {\"description\": \"Analyze information\", \"params\": {\"focus\": \"str\"}},\n",
    "        \"synthesize\": {\"description\": \"Create a synthesis\", \"params\": {\"format\": \"str?\"}},\n",
    "    },\n",
    "    prompt=(\n",
    "        \"Topic: {research_topic}\\\\nAngle: {research_angle}\\\\n\\\\n\"\n",
    "        \"Create a focused research plan with 2-3 search queries.\"\n",
    "    ),\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    max_steps=5,\n",
    ")\n",
    "\n",
    "synthesis_thought = THOUGHT(\n",
    "    name=\"synthesis\",\n",
    "    llm=llm,\n",
    "    prompt=(\n",
    "        \"Topic: {research_topic}\\\\nAngle: {research_angle}\\\\n\\\\n\"\n",
    "        \"Search results:\\\\n{search_findings}\\\\n\\\\n\"\n",
    "        \"Conversation:\\\\n{conversation_context}\\\\n\\\\n\"\n",
    "        \"Present your findings clearly and with your own perspective.\"\n",
    "    ),\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    ")\n",
    "\n",
    "deeper_thought = THOUGHT(\n",
    "    name=\"deeper_dive\",\n",
    "    llm=llm,\n",
    "    prompt=(\n",
    "        \"The user wants to go deeper:\\\\n{last_user_msg}\\\\n\\\\n\"\n",
    "        \"Previous findings:\\\\n{search_findings}\\\\n\\\\n\"\n",
    "        \"Provide a more detailed analysis.\"\n",
    "    ),\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    ")\n",
    "\n",
    "wrapup_thought = THOUGHT(\n",
    "    name=\"wrapup\",\n",
    "    llm=llm,\n",
    "    prompt=(\n",
    "        \"The user is wrapping up.\\\\n\"\n",
    "        \"Conversation:\\\\n{conversation_context}\\\\n\\\\n\"\n",
    "        \"Give a brief, warm closing with a 1-2 sentence takeaway.\"\n",
    "    ),\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    ")\n",
    "\n",
    "\n",
    "def _do_research(memory):\n",
    "    \"\"\"Execute the search pipeline and return the synthesized text.\"\"\"\n",
    "    topic = memory.get_var(\"research_topic\") or memory.last_user_msg(content_only=True)\n",
    "    angle = memory.get_var(\"research_angle\") or \"\"\n",
    "    memory.set_var(\"research_topic\", topic)\n",
    "    memory.set_var(\"research_angle\", angle)\n",
    "\n",
    "    memory = research_planner(memory)\n",
    "    plan = memory.get_var(\"research_plan_result\") or []\n",
    "\n",
    "    queries = []\n",
    "    for step in plan:\n",
    "        for task in step:\n",
    "            if task.get(\"action\") == \"search\":\n",
    "                queries.append(task.get(\"params\", {}).get(\"query\", topic))\n",
    "\n",
    "    snippets = []\n",
    "    for q in queries[:3]:\n",
    "        s = SEARCH(name=\"s\", provider=\"brave\", query=q, api_key=brave_key, max_results=4)\n",
    "        memory = s(memory)\n",
    "        for r in (memory.get_var(\"s_results\") or {}).get(\"results\", []):\n",
    "            snippets.append(\"- [{}] {}\".format(r.get(\"title\", \"\"), r.get(\"snippet\", \"\")))\n",
    "\n",
    "    memory.set_var(\"search_findings\", \"\\\\n\".join(snippets) or \"(No results.)\")\n",
    "    memory = synthesis_thought(memory)\n",
    "    return memory\n",
    "\n",
    "\n",
    "def research_turn(input_obj):\n",
    "    \"\"\"\n",
    "    Process one conversation turn.\n",
    "\n",
    "    Args:\n",
    "        input_obj: dict with \"message\" and optional \"memory_json\".\n",
    "\n",
    "    Returns:\n",
    "        dict with \"response\" and \"memory_json\" for the next turn.\n",
    "    \"\"\"\n",
    "    message = input_obj.get(\"message\", \"\")\n",
    "    memory_json = input_obj.get(\"memory_json\")\n",
    "\n",
    "    if memory_json:\n",
    "        memory = MEMORY.from_json(memory_json)\n",
    "    else:\n",
    "        memory = MEMORY()\n",
    "\n",
    "    memory.add_msg(\"user\", message, channel=\"api\")\n",
    "    conversation_context = memory.render(format=\"conversation\", max_total_length=3000)\n",
    "    memory.set_var(\"conversation_context\", conversation_context)\n",
    "\n",
    "    memory = intent_classifier(memory)\n",
    "    intent = memory.get_var(\"intent_result\")\n",
    "\n",
    "    if intent == \"new_topic\":\n",
    "        memory.set_var(\"research_topic\", message)\n",
    "        memory = discovery_thought(memory)\n",
    "        response = memory.get_var(\"discovery_result\")\n",
    "    elif intent == \"clarify\":\n",
    "        memory.set_var(\"research_angle\", message)\n",
    "        response = \"Got it. Let me search for current information. One moment...\"\n",
    "    elif intent == \"research\":\n",
    "        memory = _do_research(memory)\n",
    "        response = memory.get_var(\"synthesis_result\")\n",
    "    elif intent == \"deeper\":\n",
    "        memory = deeper_thought(memory)\n",
    "        response = memory.get_var(\"deeper_dive_result\")\n",
    "    elif intent == \"done\":\n",
    "        memory = wrapup_thought(memory)\n",
    "        response = memory.get_var(\"wrapup_result\")\n",
    "    else:\n",
    "        response = \"Could you rephrase that?\"\n",
    "\n",
    "    memory.add_msg(\"assistant\", response, channel=\"api\")\n",
    "\n",
    "    return {\n",
    "        \"response\": response,\n",
    "        \"memory_json\": memory.to_json(),\n",
    "    }\n",
    "'''\n",
    "\n",
    "print(\"Agent code prepared ({} chars)\".format(len(agent_code)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed058d",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.2 — Test the agent in the cloud before deploying\n",
    "\n",
    "`test_agent()` runs code on the ThoughtBase serverless backend without\n",
    "creating a persistent deployment.  The agent reads its API keys from\n",
    "`SECRETS` — no credentials in the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14d2b52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  4.2  Test the agent code in the cloud\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Ariel says:\n",
      "To better understand the challenges of deploying LLMs (Large Language Models) in production, I have a few questions:\n",
      "\n",
      "1. Are you referring to a specific industry or application, such as chatbots, text classification, or language translation?\n",
      "2. What is the scale of deployment you're considering - is it a small-scale pilot or a large-scale enterprise-wide rollout?\n",
      "3. Are you more concerned with technical challenges, such as model drift or computational resources, or operational challenges, like d\n",
      "\n",
      "Memory preserved: True\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"4.2  Test the agent code in the cloud\")\n",
    "\n",
    "test_result = test_agent(\n",
    "    code=agent_code,\n",
    "    fname=\"research_turn\",\n",
    "    input_obj={\n",
    "        \"message\": \"What are the biggest challenges with deploying LLMs in production?\",\n",
    "        \"memory_json\": None,\n",
    "    },\n",
    ")\n",
    "\n",
    "if isinstance(test_result, dict) and \"response\" in test_result:\n",
    "    print(\"Ariel says:\")\n",
    "    print(test_result[\"response\"][:500])\n",
    "    print(\"\\nMemory preserved:\", \"memory_json\" in test_result)\n",
    "else:\n",
    "    print(\"Raw result:\", str(test_result)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b230679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  4.3  Deploy the agent\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Deployed! Agent ID: NhLNcLc93zp01DrOkxzSNwZ7PjD3LN39KA\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"4.3  Deploy the agent\")\n",
    "\n",
    "deploy_result = deploy_agent(agent_code)\n",
    "agent_id = deploy_result.get(\"api_id\", \"\")\n",
    "print(\"Deployed! Agent ID:\", agent_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3785fabd",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5 — Multi-turn Conversation with the Deployed Agent\n",
    "\n",
    "The agent is now live.  Let us have a real conversation with it\n",
    "across multiple turns, passing memory between calls so the agent\n",
    "remembers context.\n",
    "\n",
    "Notice that the call payloads contain **only the message and memory** —\n",
    "no API keys.  Credentials come from SECRETS on the server side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e6877df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  5.1  Turn 1 — introduce a topic\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Ariel: To better understand your research needs, I have a few questions:\n",
      "\n",
      "1. What specific aspects of vector databases are you interested in learning about (e.g., architecture, use cases, performance optimization)?\n",
      "2. How do you envision using vector databases in conjunction with Large Language Models (LLMs) - are you looking to improve model training, efficient similarity searches, or something else?\n",
      "3. Are there any particular applications or industries (e.g., natural language processing, computer vi\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"5.1  Turn 1 — introduce a topic\")\n",
    "\n",
    "def _extract(result):\n",
    "    \"\"\"Pull the response string from a call_agent result.\"\"\"\n",
    "    if isinstance(result, dict):\n",
    "        return result.get(\"response\", str(result))\n",
    "    return str(result)\n",
    "\n",
    "turn1 = call_agent(agent_id, \"research_turn\", {\n",
    "    \"message\": \"I want to learn about vector databases and how they are used with LLMs.\",\n",
    "    \"memory_json\": None,\n",
    "})\n",
    "\n",
    "print(\"Ariel:\", _extract(turn1)[:500])\n",
    "memory_state = turn1.get(\"memory_json\") if isinstance(turn1, dict) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a481eb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  5.2  Turn 2 — clarify the angle\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Ariel: Got it. Let me search for current information. One moment...\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"5.2  Turn 2 — clarify the angle\")\n",
    "\n",
    "turn2 = call_agent(agent_id, \"research_turn\", {\n",
    "    \"message\": \"I care most about performance and cost at scale — millions of embeddings.\",\n",
    "    \"memory_json\": memory_state,\n",
    "})\n",
    "\n",
    "print(\"Ariel:\", _extract(turn2)[:500])\n",
    "memory_state = turn2.get(\"memory_json\") if isinstance(turn2, dict) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43ca458f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  5.3  Turn 3 — trigger research\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Ariel: Based on the search results, I've gathered information on vector databases and their use with Large Language Models (LLMs). Vector databases are designed to efficiently store and query high-dimensional vector embeddings, which are crucial for many AI and machine learning applications, including LLMs.\n",
      "\n",
      "The key benefits of using vector databases with LLMs include:\n",
      "\n",
      "1. **Efficient similarity searches**: Vector databases can measure the distance between vectors, enabling efficient similarity searches and retrieval of relevant information.\n",
      "2. **Improved performance**: Vector databases can handle millions of embeddings, making them ideal for large-scale LLM applications.\n",
      "3. **Cost-effectiveness**: Specialized vector databases can reduce the costs associated with storing and querying large amount\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"5.3  Turn 3 — trigger research\")\n",
    "\n",
    "turn3 = call_agent(agent_id, \"research_turn\", {\n",
    "    \"message\": \"Yes, go ahead and research that.\",\n",
    "    \"memory_json\": memory_state,\n",
    "})\n",
    "\n",
    "print(\"Ariel:\", _extract(turn3)[:800])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa2b622",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6 — Calling from Outside Python\n",
    "\n",
    "Your deployed agent is a standard HTTP API.  You can call it from\n",
    "any language or tool.  The caller only needs the ThoughtBase API key —\n",
    "the agent's LLM and search credentials live in SECRETS on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2d2574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  6.1  The equivalent curl command\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "You can call this agent from any terminal:\n",
      "\n",
      "curl -X POST \"https://bdxwb8xftj.execute-api.us-east-1.amazonaws.com/prod/invoke\" \\\n",
      "  -H \"Content-Type: application/json\" \\\n",
      "  -d '{\n",
      "    \"api_key\": \"qL58Gs2y...\",\n",
      "    \"api_id\": \"NhLNcLc93zp01DrOkxzSNwZ7PjD3LN39KA\",\n",
      "    \"fname\": \"research_turn\",\n",
      "    \"encoded\": 1,\n",
      "    \"zipped\": 0,\n",
      "    \"input\": {\n",
      "      \"message\": \"What is retrieval-augmented generation?\",\n",
      "      \"memory_json\": null\n",
      "    }\n",
      "  }'\n",
      "\n",
      "(Replace api_key with your full ThoughtBase key.)\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"6.1  The equivalent curl command\")\n",
    "\n",
    "curl_cmd = '''curl -X POST \"{exec_url}\" \\\\\n",
    "  -H \"Content-Type: application/json\" \\\\\n",
    "  -d '{{\n",
    "    \"api_key\": \"{api_key}\",\n",
    "    \"api_id\": \"{agent_id}\",\n",
    "    \"fname\": \"research_turn\",\n",
    "    \"encoded\": 1,\n",
    "    \"zipped\": 0,\n",
    "    \"input\": {{\n",
    "      \"message\": \"What is retrieval-augmented generation?\",\n",
    "      \"memory_json\": null\n",
    "    }}\n",
    "  }}'\n",
    "'''.format(\n",
    "    exec_url=\"https://bdxwb8xftj.execute-api.us-east-1.amazonaws.com/prod/invoke\",\n",
    "    api_key=thb_key[:8] + \"...\" if len(thb_key) > 8 else \"<your-key>\",\n",
    "    agent_id=agent_id,\n",
    ")\n",
    "\n",
    "print(\"You can call this agent from any terminal:\\n\")\n",
    "print(curl_cmd)\n",
    "print(\"(Replace api_key with your full ThoughtBase key.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69ebf308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  6.2  Standalone Python script (no thoughtbase import)\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Save this as call_agent.py and run it standalone:\n",
      "\n",
      "import requests\n",
      "\n",
      "EXEC_URL = \"https://bdxwb8xftj.execute-api.us-east-1.amazonaws.com/prod/invoke\"\n",
      "API_KEY  = \"<your-thoughtbase-api-key>\"\n",
      "AGENT_ID = \"NhLNcLc93zp01DrOkxzSNwZ7PjD3LN39KA\"\n",
      "\n",
      "\n",
      "def call(message, memory_json=None):\n",
      "    \"\"\"Call the deployed research agent over HTTP.\n",
      "\n",
      "    No LLM credentials needed — the agent reads them from SECRETS\n",
      "    on the server side.\n",
      "    \"\"\"\n",
      "    body = {\n",
      "        \"api_key\": API_KEY,\n",
      "        \"api_id\": AGENT_ID,\n",
      "        \"fname\": \"research_turn\",\n",
      "        \"encoded\": 1,\n",
      "        \"zipped\": 0,\n",
      "        \"input\": {\n",
      "            \"message\": message,\n",
      "            \"memory_json\": memory_json,\n",
      "        },\n",
      "    }\n",
      "    resp = requests.post(EXEC_URL, json=body)\n",
      "    data = resp.json()\n",
      "    try:\n",
      "        return data[\"output\"][\"result\"]\n",
      "    except Exception:\n",
      "        return data\n",
      "\n",
      "\n",
      "# --- Usage ---\n",
      "result = call(\"What is the current state of quantum computing?\")\n",
      "print(\"Agent says:\", result.get(\"response\"))\n",
      "\n",
      "# Multi-turn — pass memory forward:\n",
      "result2 = call(\"Tell me more about error correction.\", result.get(\"memory_json\"))\n",
      "print(\"Agent says:\", result2.get(\"response\"))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"6.2  Standalone Python script (no thoughtbase import)\")\n",
    "\n",
    "standalone_script = '''import requests\n",
    "\n",
    "EXEC_URL = \"https://bdxwb8xftj.execute-api.us-east-1.amazonaws.com/prod/invoke\"\n",
    "API_KEY  = \"<your-thoughtbase-api-key>\"\n",
    "AGENT_ID = \"{agent_id}\"\n",
    "\n",
    "\n",
    "def call(message, memory_json=None):\n",
    "    \"\"\"Call the deployed research agent over HTTP.\n",
    "\n",
    "    No LLM credentials needed — the agent reads them from SECRETS\n",
    "    on the server side.\n",
    "    \"\"\"\n",
    "    body = {{\n",
    "        \"api_key\": API_KEY,\n",
    "        \"api_id\": AGENT_ID,\n",
    "        \"fname\": \"research_turn\",\n",
    "        \"encoded\": 1,\n",
    "        \"zipped\": 0,\n",
    "        \"input\": {{\n",
    "            \"message\": message,\n",
    "            \"memory_json\": memory_json,\n",
    "        }},\n",
    "    }}\n",
    "    resp = requests.post(EXEC_URL, json=body)\n",
    "    data = resp.json()\n",
    "    try:\n",
    "        return data[\"output\"][\"result\"]\n",
    "    except Exception:\n",
    "        return data\n",
    "\n",
    "\n",
    "# --- Usage ---\n",
    "result = call(\"What is the current state of quantum computing?\")\n",
    "print(\"Agent says:\", result.get(\"response\"))\n",
    "\n",
    "# Multi-turn — pass memory forward:\n",
    "result2 = call(\"Tell me more about error correction.\", result.get(\"memory_json\"))\n",
    "print(\"Agent says:\", result2.get(\"response\"))\n",
    "'''.format(agent_id=agent_id)\n",
    "\n",
    "print(\"Save this as call_agent.py and run it standalone:\\n\")\n",
    "print(standalone_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2df1c32",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7 — What You Have Deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9abc2a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  7.1  List all deployed agents\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "You have 6 deployed agent(s):\n",
      "  - t6mR0djfIxBJLoXjDwp0jvCDF4hYGAEL49\n",
      "  - OOAt4aJrjfVJaMZE31erYvvjhqbGpdyxZP\n",
      "  - hya6UpZrvAQzPqNltsczK2NQ25BFs81Te3\n",
      "  - cW3X56SRSWTZxOsRMqJC0kvgRafuAdeuE2\n",
      "  - DvrtH1oMXHbC2doIu4x7ipDNNmGsU58QSE\n",
      "  - NhLNcLc93zp01DrOkxzSNwZ7PjD3LN39KA\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"7.1  List all deployed agents\")\n",
    "\n",
    "agents = list_agents()\n",
    "\n",
    "if isinstance(agents, dict) and \"api_list\" in agents:\n",
    "    agent_ids = agents[\"api_list\"]\n",
    "    print(\"You have {} deployed agent(s):\".format(len(agent_ids)))\n",
    "    for aid in agent_ids:\n",
    "        print(\"  -\", aid)\n",
    "elif isinstance(agents, list):\n",
    "    print(\"You have {} deployed agent(s):\".format(len(agents)))\n",
    "    for a in agents:\n",
    "        aid = a.get(\"api_id\", a.get(\"id\", str(a)))\n",
    "        print(\"  -\", aid)\n",
    "else:\n",
    "    print(\"Agents:\", agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68baf7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "  7.2  Summary\n",
      "══════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Simple agent ID : DvrtH1oMXHbC2doIu4x7ipDNNmGsU58QSE\n",
      "Research agent ID: NhLNcLc93zp01DrOkxzSNwZ7PjD3LN39KA\n",
      "\n",
      "Both agents are now live cloud APIs.\n",
      "They auto-scale, require no servers, and cost only when called.\n",
      "\n",
      "To update the research agent later:\n",
      "  from thoughtbase import update_agent\n",
      "  update_agent(\"NhLNcLc93zp01DrOkxzSNwZ7PjD3LN39KA\", new_code)\n"
     ]
    }
   ],
   "source": [
    "print_heading(\"7.2  Summary\")\n",
    "\n",
    "print(\"Simple agent ID :\", simple_agent_id)\n",
    "print(\"Research agent ID:\", agent_id)\n",
    "print()\n",
    "print(\"Both agents are now live cloud APIs.\")\n",
    "print(\"They auto-scale, require no servers, and cost only when called.\")\n",
    "print()\n",
    "print(\"To update the research agent later:\")\n",
    "print('  from thoughtbase import update_agent')\n",
    "print('  update_agent(\"{}\", new_code)'.format(agent_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5ffba0",
   "metadata": {},
   "source": [
    "---\n",
    "## Recap — The Full Journey\n",
    "\n",
    "Across four scripts, you have:\n",
    "\n",
    "| Script | What you built |\n",
    "|--------|---------------|\n",
    "| **01** | LLM calls, MEMORY state management, THOUGHT reasoning |\n",
    "| **02** | DECIDE classification, PLAN generation, ACTION primitives |\n",
    "| **03** | A conversational research agent with personality |\n",
    "| **04** | Secrets, deployment, multi-turn cloud API, external access |\n",
    "\n",
    "The entire stack — from a single LLM call to a production API —\n",
    "was built with **6 primitives**: LLM, MEMORY, THOUGHT, DECIDE,\n",
    "PLAN, and ACTION.\n",
    "\n",
    "That is ThoughtFlow + ThoughtBase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90329de-0683-4d73-8392-bc8fde22c458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771666ea-4a52-4e64-9bd2-9d6fd6573bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea62b1f4-484a-4260-9660-ac99b52ac022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb9b9a3-f53a-4e0a-9e24-c2ee6d73994d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc905e6-cf18-469e-bf92-ef2ec0b17a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea45b334-aff4-4b8c-a232-402f02496e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "701efc20-b89f-45a6-a33a-e827d434b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [END!!]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9917d344-afc3-4162-b5e9-f8900d0c9b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e6f970-923d-4cce-8b36-09573cdda413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c041a0e5-23b7-425b-859d-d0b7c4a6809c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
